# TEXT DATA ANALYSIS WITH NLTK

**Project Overview**  
This project demonstrates natural language processing (NLP) using Python's NLTK library. The goal was to tokenize the words, removing common stop words, analyzing word frequencies, and visualizing
the word distributions.

**Text**  
The text used for this project was an example sentence provided in the jupyter file.

**Tools**  
- Python
- NLTK (Natural Language Toolkit)
- Matplotlib
  
**Workflow**
1. Tokenize the text using the sent_tokenize and word_tokenize functions
2. Analyze common word occurences and plot frequency distribution using Matplotlib
3. Removed common english stopwords (ex and) and kept meaningful ones
4. Basic text cleaning

**Run Instructions**
1. Clone the repo: git clone https://github.com/Ayden939/nltk-text-analysis.git
2. Open the Jupyter file (Jupyter Notebook or Visual Studio Code), and you can run it step by step
